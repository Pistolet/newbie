## network 설정


[root@hadoopserver ~]# cd /etc/sysconfig/network-scripts


# ifcfg-eth0 수정

[root@hadoopserver network-scripts]# vi ifcfg-eth0

ONBOOT=yes

# ifcfg-eth1 수정

[root@hadoopserver  network-scripts]# vi ifcfg-eth1


ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=none
NETMASK=255.255.255.0
IPADDR=192.168.56.101

[root@hadoopserver  network-scripts]# service network restart



# hostname 설정

[root@hadoopserver ~]# vi /etc/hosts


192.168.56.101 hadoopserver


## VM VirtualBox 설정


[root@hadoopserver  ~]# yum -y install gcc make kernel-devel kernel sources kernel-headers
[root@hadoopserver  ~]# yum -y groupinstall "Development Tools"

메뉴 장치 - 게스트  확장 CD 이미지 삽입 - 실행


[root@hadoopserver  ~]# reboot



## 방화벽 해지

[root@hadoopserver Desktop]# iptables -F
[root@hadoopserver Desktop]# iptables -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
       

## jdk 설정

[root@hadoopserver Desktop]# mkdir -p /usr/java
[root@hadoopserver Desktop]# cp /media/sf_hadoop/jdk-7u80-linux-x64.tar.gz /usr/java

[root@hadoopserver Desktop]# cd /usr/java
[root@hadoopserver java]# ll
total 149940
-rwxr-x---. 1 root root 153530841 Apr 23 15:39 jdk-7u80-linux-x64.tar.gz
[root@hadoopserver java]# tar xvfz jdk-7u80-linux-x64.tar.gz 


[root@hadoopserver java]# ll
total 149944
drwxr-xr-x. 8 uucp  143      4096 Apr 11  2015 jdk1.7.0_80
-rwxr-x---. 1 root root 153530841 Apr 23 15:39 jdk-7u80-linux-x64.tar.gz

[root@hadoopserver java]# vi /etc/profile

export JAVA_HOME=/usr/java/jdk1.7.0_80
export PATH=$PATH:$JAVA_HOME/bin
export CLASS_PATH="."


[root@hadoopserver java]# source /etc/profile
[root@hadoopserver java]# java -version
java version "1.7.0_09-icedtea"
OpenJDK Runtime Environment (rhel-2.3.4.1.el6_3-x86_64)
OpenJDK 64-Bit Server VM (build 23.2-b09, mixed mode)


[root@hadoopserver java] which java
/usr/bin/java

[root@hadoopserver java]# update-alternatives --install "/usr/bin/java" "java" "/usr/java/jdk1.7.0_80/bin/java" 1

[root@hadoopserver java]# update-alternatives --config java

There are 3 programs which provide 'java'.

  Selection    Command
-----------------------------------------------
*+ 1           /usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java
   2           /usr/lib/jvm/jre-1.6.0-openjdk.x86_64/bin/java
   3           /usr/java/jdk1.7.0_80/bin/java

Enter to keep the current selection[+], or type selection number: 3


[root@hadoopserver java]# java -version
java version "1.7.0_80"
Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)


##  프로토콜 버퍼 설치 ##
# 구글에서 만든 오픈소스 직렬화 라이브러리 
# 이기종 서버간의 데이터 통신은 서로 다른 종류의 언어로 개발된 시스템간의 데이터를 전달하는 방식은
# text format, binary format 데이터를 이용하는 방법
# text format 방식은 데이터를 이해하기 쉽고, 각 언어별로 파서를 제공한다. 단점은 테이터 자체가 크다, 파서의 성능이 떨어진다.
# binary format 방식은 데이터 크기가 작다. 성능이 좋다.단점은 바이너리 코드를 만들고 해독해야하는 모듈을 만들어야 하는 부담
# 하둡2 에서 데몬간의 데이터 통신을 위해 protocol buffer를 사용
# https://github.com/google/protobuf/releases/tag/v2.5.0

[root@hadoopserver ~]# cp /media/sf_hadoop/protobuf-2.5.0.tar.gz /usr/local
[root@hadoopserver ~]# cd /usr/local
[root@hadoopserver local]# ll

[root@hadoopserver local]#  tar xvfz protobuf-2.5.0.tar.gz 
[root@hadoopserver local]# cd protobuf-2.5.0

[root@hadoopserver protobuf-2.5.0]# ./configure

[root@hadoopserver protobuf-2.5.0]# make

[root@hadoopserver protobuf-2.5.0]# make install

[root@hadoopserver protobuf-2.5.0]# protoc --version
libprotoc 2.5.0



# 사용자 그룹 생성

[root@hadoopserver ~]# groupadd hadoop

# 유저생성

[root@hadoopserver ~]# useradd -g hadoop -G vboxsf -m hadoop

# 패스워드 설정

[root@hadoopserver ~]# passwd hadoop

# 유저 생성 확인

[root@hadoopserver ~]# cat /etc/passwd

[root@hadoopserver ~]# cat /etc/group

# 사용자가 소속된 그룹 확인

[root@hadoopserver ~]# groups hadoop
hadoop : hadoop vboxsf




## 하둡 설치 
# wget "https://archive.apache.org/dist/hadoop/core/hadoop-2.7.2/hadoop-2.7.2.tar.gz"

[root@hadoopserver ~]# su - hadoop

[hadoop@hadoopserver ~]$ cp /media/sf_hadoop/hadoop-2.7.2.tar.gz /home/hadoop
[hadoop@hadoopserver ~]$ ll
total 207080
-rwxrwx---. 1 hadoop hadoop 212046774 Apr 23 16:06 hadoop-2.7.2.tar.gz


[hadoop@hadoopserver ~]$ tar xvzf hadoop-2.7.2.tar.gz

[hadoop@hadoopserver ~]$ ll
total 207084
drwxr-xr-x. 9 hadoop hadoop      4096 Jan 26  2016 hadoop-2.7.2
-rwxrwx---. 1 hadoop hadoop 212046774 Apr 23 16:06 hadoop-2.7.2.tar.gz

[hadoop@hadoopserver ~]$ vi .bashrc

export JAVA_HOME=/usr/java/jdk1.7.0_80
export HADOOP_HOME=/home/hadoop/hadoop-2.7.2
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

[hadoop@hadoopserver ~]$ source .bashrc

[hadoop@hadoopserver ~]$ java -version
java version "1.7.0_80"
Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)

## 공개키 생성 
[hadoop@hadoopserver ~]$ rm -rf .ssh 
[hadoop@hadoopserver ~]$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): 
Created directory '/home/hadoop/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/hadoop/.ssh/id_rsa.
Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.
The key fingerprint is:
b8:e5:55:fd:f9:72:4d:48:e6:47:22:bd:44:cb:41:7d hadoop@hadoopserver
The key's randomart image is:
+--[ RSA 2048]----+
|             .+. |
|             = oE|
|            o X o|
|       .   . * *.|
|      . S .   +.+|
|       + .     oo|
|      . .     . +|
|               o |
|                 |
+-----------------+

[hadoop@hadoopserver ~]$  ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@192.168.56.101
hadoop@192.168.56.101's password: 
Now try logging into the machine, with "ssh 'hadoop@192.168.56.101'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.


[hadoop@hadoopserver ~]$ ssh hadoop@192.168.56.101
Last login: Mon Apr 23 16:10:50 2018 from hadoopserver

## 하둡 환경설정 파일 수정 ##

[hadoop@hadoopserver ~]$ cd /home/hadoop/hadoop-2.7.2/etc/hadoop/

[hadoop@hadoopserver hadoop]$ vi hadoop-env.sh


# jdk 설치 경로 수정

export JAVA_HOME=/usr/java/jdk1.7.0_80

# 하둡 데몬 pid 저장 경로 수정

export HADOOP_PID_DIR=/home/hadoop/hadoop-2.7.2/pids


## 보조네임노드 실행 서버 설정

[hadoop@hadoopserver hadoop]$ vi masters

192.168.56.101

# 데이터노드 실행 서버 설정

[hadoop@hadoopserver hadoop]$ vi slaves

192.168.56.101


# HDFS, MapReduce 공통적으로 사용할 환경정보 설정

[hadoop@hadoopserver hadoop]$  vi core-site.xml

<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://hadoopserver:9010</value>
 </property>
</configuration>


# HDFS 환경정보 설정

[hadoop@hadoopserver hadoop]$  vi hdfs-site.xml

<configuration>
 <property>
  <name>dfs.replication</name>
  <value>1</value>
 </property>
 <property>
  <name>dfs.namenode.name.dir</name>
  <value>/home/hadoop/data/dfs/namenode</value>
 </property>
 <property>
  <name>dfs.namenode.checkpoint.dir</name>
  <value>/home/hadoop/data/dfs/namesecondary</value>
 </property>
 <property>
  <name>dfs.datanode.data.dir</name>
  <value>/home/hadoop/data/dfs/datanode</value>
 </property>
 <property>
  <name>dfs.http.address</name>
  <value>hadoopserver:50070</value>
 </property>
 <property>
  <name>dfs.secondary.http.address</name>
  <value>hadoopserver:50090</value>
 </property>
</configuration>


# MapReduce 환경정보 설정

[hadoop@hadoopserver hadoop]$ cp mapred-site.xml.template mapred-site.xml
[hadoop@hadoopserver hadoop]$ vi mapred-site.xml

<configuration>
 <property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
 </property>
</configuration>


# yarn 을 실행하는 쉘스크립트 파일에 필요한 환경변수 설정, 기본으로 설정되어있다.

[hadoop@server01 hadoop]$ vi yarn-env.sh

JAVA=$JAVA_HOME/bin/java
JAVA_HEAP_MAX=-Xmx1000m


# yarn에서 사용할 환경정보 설정

[hadoop@server01 hadoop]$ vi yarn-site.xml

<configuration>
 <property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
 </property>
 <property>
  <name>yarn.nodemanager.aux-services.mapreduce_suffle.class</name>
  <value>org.apache.hadoop.mapred.ShuffleHandler</value>
 </property>
 <property>
  <name>yarn.nodemanager.local-dirs</name>
  <value>/home/hadoop/data/yarn/nm-local-dir</value>
 </property>
 <property>
  <name>yarn.resourcemanager.fs.state-store.uri</name>
  <value>/home/hadoop/data/yarn/system/rmstore</value>
 </property>
 <property>
  <name>yarn.resourcemanager.hostname</name>
  <value>hadoopserver</value>
 </property>
 <property>
  <name>yarn.web-proxy.address</name>
  <value>0.0.0.0:8089</value>
 </property>
</configuration>



                                                                                               
### 
하둡 데몬 시작
##

[hadoop@hadoopserver hadoop]$ hdfs namenode -format

[hadoop@hadoopserver hadoop]$ start-dfs.sh

[hadoop@hadoopserver hadoop]$ start-yarn.sh

[hadoop@hadoopserver hadoop]$ mr-jobhistory-daemon.sh start historyserver

[hadoop@hadoopserver hadoop]$ yarn-daemon.sh start proxyserver

[hadoop@hadoopserver hadoop]$ jps
10409 ResourceManager
10060 DataNode
10869 WebAppProxyServer
9961 NameNode
10918 Jps
10222 SecondaryNameNode
10509 NodeManager
10793 JobHistoryServer





## 
하둡 데몬 종료
##


[hadoop@hadoopserver hadoop]$  stop-yarn.sh

[hadoop@hadoopserver hadoop]$  stop-dfs.sh

[hadoop@hadoopserver hadoop]$  mr-jobhistory-daemon.sh stop historyserver


